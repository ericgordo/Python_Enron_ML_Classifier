{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries: 146\n",
      "METTS MARK\n",
      "BAXTER JOHN C\n",
      "ELLIOTT STEVEN\n",
      "CORDES WILLIAM R\n",
      "HANNON KEVIN P\n",
      "MORDAUNT KRISTINA M\n",
      "MEYER ROCKFORD G\n",
      "MCMAHON JEFFREY\n",
      "HORTON STANLEY C\n",
      "PIPER GREGORY F\n",
      "HUMPHREY GENE E\n",
      "UMANOFF ADAM S\n",
      "BLACHMAN JEREMY M\n",
      "SUNDE MARTIN\n",
      "GIBBS DANA R\n",
      "LOWRY CHARLES P\n",
      "COLWELL WESLEY\n",
      "MULLER MARK S\n",
      "JACKSON CHARLENE R\n",
      "WESTFAHL RICHARD K\n",
      "WALTERS GARETH W\n",
      "WALLS JR ROBERT H\n",
      "KITCHEN LOUISE\n",
      "CHAN RONNIE\n",
      "BELFER ROBERT\n",
      "SHANKMAN JEFFREY A\n",
      "WODRASKA JOHN\n",
      "BERGSIEKER RICHARD P\n",
      "URQUHART JOHN A\n",
      "BIBI PHILIPPE A\n",
      "RIEKER PAULA H\n",
      "WHALEY DAVID A\n",
      "BECK SALLY W\n",
      "HAUG DAVID L\n",
      "ECHOLS JOHN B\n",
      "MENDELSOHN JOHN\n",
      "HICKERSON GARY J\n",
      "CLINE KENNETH W\n",
      "LEWIS RICHARD\n",
      "HAYES ROBERT E\n",
      "MCCARTY DANNY J\n",
      "KOPPER MICHAEL J\n",
      "LEFF DANIEL P\n",
      "LAVORATO JOHN J\n",
      "BERBERIAN DAVID\n",
      "DETMERING TIMOTHY J\n",
      "WAKEHAM JOHN\n",
      "POWERS WILLIAM\n",
      "GOLD JOSEPH\n",
      "BANNANTINE JAMES M\n",
      "DUNCAN JOHN H\n",
      "SHAPIRO RICHARD S\n",
      "SHERRIFF JOHN R\n",
      "SHELBY REX\n",
      "LEMAISTRE CHARLES\n",
      "DEFFNER JOSEPH M\n",
      "KISHKILL JOSEPH G\n",
      "WHALLEY LAWRENCE G\n",
      "MCCONNELL MICHAEL S\n",
      "PIRO JIM\n",
      "DELAINEY DAVID W\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      "WROBEL BRUCE\n",
      "LINDHOLM TOD A\n",
      "MEYER JEROME J\n",
      "LAY KENNETH L\n",
      "BUTTS ROBERT H\n",
      "OLSON CINDY K\n",
      "MCDONALD REBECCA\n",
      "CUMBERLAND MICHAEL S\n",
      "GAHN ROBERT S\n",
      "MCCLELLAN GEORGE\n",
      "HERMANN ROBERT J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "HAEDICKE MARK E\n",
      "BOWEN JR RAYMOND M\n",
      "GILLIS JOHN\n",
      "FITZGERALD JAY L\n",
      "MORAN MICHAEL P\n",
      "REDMOND BRIAN L\n",
      "BAZELIDES PHILIP J\n",
      "BELDEN TIMOTHY N\n",
      "DURAN WILLIAM D\n",
      "THORN TERENCE H\n",
      "FASTOW ANDREW S\n",
      "FOY JOE\n",
      "CALGER CHRISTOPHER F\n",
      "RICE KENNETH D\n",
      "KAMINSKI WINCENTY J\n",
      "LOCKHART EUGENE E\n",
      "COX DAVID\n",
      "OVERDYKE JR JERE C\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "STABLER FRANK\n",
      "SKILLING JEFFREY K\n",
      "BLAKE JR. NORMAN P\n",
      "SHERRICK JEFFREY B\n",
      "PRENTICE JAMES\n",
      "GRAY RODNEY\n",
      "PICKERING MARK R\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "KEAN STEVEN J\n",
      "TOTAL\n",
      "FOWLER PEGGY\n",
      "WASAFF GEORGE\n",
      "WHITE JR THOMAS E\n",
      "CHRISTODOULOU DIOMEDES\n",
      "ALLEN PHILLIP K\n",
      "SHARP VICTORIA T\n",
      "JAEDICKE ROBERT\n",
      "WINOKUR JR. HERBERT S\n",
      "BROWN MICHAEL\n",
      "BADUM JAMES P\n",
      "HUGHES JAMES A\n",
      "REYNOLDS LAWRENCE\n",
      "DIMICHELE RICHARD G\n",
      "BHATNAGAR SANJAY\n",
      "CARTER REBECCA C\n",
      "BUCHANAN HAROLD G\n",
      "YEAP SOON\n",
      "MURRAY JULIA H\n",
      "GARLAND C KEVIN\n",
      "DODSON KEITH\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "DIETRICH JANET R\n",
      "DERRICK JR. JAMES V\n",
      "FREVERT MARK A\n",
      "PAI LOU L\n",
      "BAY FRANKLIN R\n",
      "HAYSLETT RODERICK J\n",
      "FUGH JOHN L\n",
      "FALLON JAMES B\n",
      "KOENIG MARK E\n",
      "SAVAGE FRANK\n",
      "IZZO LAWRENCE L\n",
      "TILNEY ELIZABETH A\n",
      "MARTIN AMANDA K\n",
      "BUY RICHARD B\n",
      "GRAMM WENDY L\n",
      "CAUSEY RICHARD A\n",
      "TAYLOR MITCHELL S\n",
      "DONAHUE JR JEFFREY M\n",
      "GLISAN JR BEN F\n"
     ]
    }
   ],
   "source": [
    "#Create Pandas Dataframe\n",
    "enron_df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees=np.array(data_dict.keys())\n",
    "enron_df.set_index(employees, inplace=True)\n",
    "\n",
    "#Investigation of Entry Names\n",
    "print \"Number of Entries:\", len(enron_df) \n",
    "\n",
    "for person in enron_df.iterrows():\n",
    "    print person[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are two seapearate names that Are Issues:<br>\n",
    "'THE TRAVEL AGENCY IN THE PARK' <br>\n",
    "'TOTAL'<br>\n",
    "These entries will be deleted as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI's: 18\n"
     ]
    }
   ],
   "source": [
    "#Number of POIs\n",
    "count=0\n",
    "for person in data_dict:\n",
    "    if data_dict[person][\"poi\"]==True:\n",
    "        count+=1      \n",
    "print \"POI's:\",count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHALEY DAVID A 18\n",
      "WROBEL BRUCE 18\n",
      "LOCKHART EUGENE E 20\n",
      "THE TRAVEL AGENCY IN THE PARK 18\n",
      "GRAMM WENDY L 18\n"
     ]
    }
   ],
   "source": [
    "# people with too many Nans\n",
    "for person in data_dict:\n",
    "    NaN=0\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            NaN += 1\n",
    "    if NaN >= 18:\n",
    "        print person, NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonus                          NaN\n",
      "deferral_payments              NaN\n",
      "deferred_income                NaN\n",
      "director_fees                  NaN\n",
      "email_address                  NaN\n",
      "exercised_stock_options        NaN\n",
      "expenses                       NaN\n",
      "from_messages                  NaN\n",
      "from_poi_to_this_person        NaN\n",
      "from_this_person_to_poi        NaN\n",
      "loan_advances                  NaN\n",
      "long_term_incentive            NaN\n",
      "other                          NaN\n",
      "poi                          False\n",
      "restricted_stock               NaN\n",
      "restricted_stock_deferred      NaN\n",
      "salary                         NaN\n",
      "shared_receipt_with_poi        NaN\n",
      "to_messages                    NaN\n",
      "total_payments                 NaN\n",
      "total_stock_value              NaN\n",
      "Name: LOCKHART EUGENE E, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Take a look at Eugene Lockhart\n",
    "print enron_df.loc['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'LOCKHART EUGENE E' literally only has one data entry -- FALSE for POI -- and no other Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Remove outliers\n",
    "try:\n",
    "    enron_df.drop('THE TRAVEL AGENCY IN THE PARK', inplace=True)\n",
    "    enron_df.drop('TOTAL', inplace=True)\n",
    "    enron_df.drop('LOCKHART EUGENE E', inplace=True)\n",
    "except:\n",
    "    print \"Outliers Already Removed\"'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary <type 'str'>\n",
      "to_messages <type 'str'>\n",
      "deferral_payments <type 'str'>\n",
      "total_payments <type 'str'>\n",
      "exercised_stock_options <type 'str'>\n",
      "bonus <type 'str'>\n",
      "restricted_stock <type 'str'>\n",
      "shared_receipt_with_poi <type 'str'>\n",
      "restricted_stock_deferred <type 'str'>\n",
      "total_stock_value <type 'str'>\n",
      "expenses <type 'str'>\n",
      "loan_advances <type 'str'>\n",
      "from_messages <type 'str'>\n",
      "other <type 'str'>\n",
      "from_this_person_to_poi <type 'str'>\n",
      "poi <type 'str'>\n",
      "director_fees <type 'str'>\n",
      "deferred_income <type 'str'>\n",
      "long_term_incentive <type 'str'>\n",
      "email_address <type 'str'>\n",
      "from_poi_to_this_person <type 'str'>\n",
      "Number of Feautres: 21\n",
      "\n",
      "Number of salary NaNs:  51\n",
      "Number of to_messages NaNs:  60\n",
      "Number of deferral_payments NaNs:  107\n",
      "Number of total_payments NaNs:  21\n",
      "Number of exercised_stock_options NaNs:  44\n",
      "Number of bonus NaNs:  64\n",
      "Number of restricted_stock NaNs:  36\n",
      "Number of shared_receipt_with_poi NaNs:  60\n",
      "Number of restricted_stock_deferred NaNs:  128\n",
      "Number of total_stock_value NaNs:  20\n",
      "Number of expenses NaNs:  51\n",
      "Number of loan_advances NaNs:  142\n",
      "Number of from_messages NaNs:  60\n",
      "Number of other NaNs:  53\n",
      "Number of from_this_person_to_poi NaNs:  60\n",
      "Number of poi NaNs:  0\n",
      "Number of director_fees NaNs:  129\n",
      "Number of deferred_income NaNs:  97\n",
      "Number of long_term_incentive NaNs:  80\n",
      "Number of email_address NaNs:  35\n",
      "Number of from_poi_to_this_person NaNs:  60\n"
     ]
    }
   ],
   "source": [
    "#Number of Features and their Types\n",
    "features=0\n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        print feature, type(feature)\n",
    "        features+=1\n",
    "    break\n",
    "print \"Number of Feautres:\", features\n",
    "print''\n",
    "\n",
    "#Number of NaN's for Each Feature\n",
    "for feature in data_dict['METTS MARK'].keys():\n",
    "    Nans=0    \n",
    "    for person in data_dict:\n",
    "        if data_dict[person][feature]=='NaN':\n",
    "            Nans += 1\n",
    "    print \"Number of\", feature, \"NaNs: \", Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'bonus', u'deferral_payments', u'deferred_income', u'director_fees',\n",
      "       u'email_address', u'exercised_stock_options', u'expenses',\n",
      "       u'from_messages', u'from_poi_to_this_person',\n",
      "       u'from_this_person_to_poi', u'loan_advances', u'long_term_incentive',\n",
      "       u'other', u'poi', u'restricted_stock', u'restricted_stock_deferred',\n",
      "       u'salary', u'shared_receipt_with_poi', u'to_messages',\n",
      "       u'total_payments', u'total_stock_value', u'combined_emails'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### Create new feature(s)\n",
    "# POI_From_To_Ratio is just the # of emails to a poi divided by emails from a poi to this person\n",
    "enron_df['combined_emails'] = (enron_df['from_messages'].astype(float)) + (enron_df['from_poi_to_this_person'].astype(float)) +\\\n",
    "(enron_df['to_messages'].astype(float)) + (enron_df['from_this_person_to_poi'].astype(float)) \n",
    "   \n",
    "enron_df['combined_emails'].fillna(value=0, inplace=True)\n",
    "        \n",
    "print enron_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METTS MARK           875.0\n",
       "BAXTER JOHN C          0.0\n",
       "ELLIOTT STEVEN         0.0\n",
       "CORDES WILLIAM R     786.0\n",
       "HANNON KEVIN P      1130.0\n",
       "Name: combined_emails, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_df['combined_emails'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "['to_messages', 'deferral_payments', 'expenses', 'poi', 'long_term_incentive', 'email_address', 'from_poi_to_this_person', 'deferred_income', 'combined_emails', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'from_messages', 'other', 'director_fees', 'bonus', 'total_stock_value', 'from_this_person_to_poi', 'restricted_stock', 'salary', 'total_payments', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "### RETURN to DICTIONARY\n",
    "data_dict=enron_df.to_dict('index')  \n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "print len(my_dataset)\n",
    "print my_dataset['METTS MARK'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Feature Length: 21\n",
      "\n",
      " Features List Now is: \n",
      "16 ['poi', 'salary', 'total_payments', 'exercised_stock_options', 'bonus', 'director_fees', 'deferred_income', 'shared_receipt_with_poi', 'loan_advances', 'other', 'total_stock_value', 'long_term_incentive', 'expenses', 'restricted_stock', 'from_poi_to_this_person', 'from_this_person_to_poi']\n"
     ]
    }
   ],
   "source": [
    "### KBEst to select what features to use.\n",
    "\n",
    "temp_features = ['poi','to_messages', \n",
    "                 'deferral_payments','combined_emails', 'expenses',\n",
    "                 'long_term_incentive', 'from_poi_to_this_person',\n",
    "                 'deferred_income','restricted_stock_deferred', \n",
    "                 'shared_receipt_with_poi', 'loan_advances', \n",
    "                 'from_messages', 'other','director_fees', \n",
    "                 'bonus', 'total_stock_value', \n",
    "                 'from_this_person_to_poi', 'restricted_stock',\n",
    "                 'salary', 'total_payments', 'exercised_stock_options']\n",
    "\n",
    "print \"Starting Feature Length:\", len(temp_features)\n",
    "# Create Data \n",
    "data = featureFormat(data_dict, temp_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_list=['poi']\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "feature_counts={}\n",
    "kf=StratifiedShuffleSplit(labels, n_iter=5, random_state=50)\n",
    "\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train= [features[ii] for ii in train_indices]\n",
    "    features_test= [features[ii] for ii in test_indices]\n",
    "    labels_train= [labels[ii] for ii in train_indices]\n",
    "    labels_test= [labels[ii] for ii in test_indices]\n",
    "    \n",
    "    #Select Features\n",
    "    kbest=SelectKBest(k=14)\n",
    "    scaler=MinMaxScaler()\n",
    "    features_scaled = scaler.fit_transform(features_train, labels_train )\n",
    "    kbest.fit(features_scaled, labels_train )\n",
    "    features_to_use=kbest.get_support()\n",
    "    for i, item in enumerate(features_to_use):\n",
    "        if item:\n",
    "            feature=temp_features[i + 1 ]\n",
    "            if feature in feature_counts:\n",
    "                feature_counts[feature]+=1\n",
    "            else:\n",
    "                feature_counts[feature]=1\n",
    "\n",
    "for feature in feature_counts:\n",
    "    if feature_counts[feature] > 1:\n",
    "        features_list.append(feature)\n",
    "\n",
    "print \"\\n Features List Now is: \\n\",len(features_list), features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re Create Data With New List\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Try a varity of classifiers\n",
    "### Definition of Classifier Tester Function\n",
    "def test_class(clssf):\n",
    "    kf=StratifiedShuffleSplit(labels, test_size=0.1,n_iter=20)\n",
    "    accuracy=0\n",
    "    precision=0\n",
    "    recall=0\n",
    "    for train_indices, test_indices in kf:\n",
    "        features_train= [features[ii] for ii in train_indices]\n",
    "        features_test= [features[ii] for ii in test_indices]\n",
    "        labels_train= [labels[ii] for ii in train_indices]\n",
    "        labels_test= [labels[ii] for ii in test_indices]\n",
    "        \n",
    "        pca=PCA(n_components= 6)\n",
    "        pipe=Pipeline([\n",
    "            (\"Classifier\",clssf)\n",
    "        ])\n",
    "\n",
    "        pipe.fit(features_train,labels_train)\n",
    "        pred=pipe.predict(features_test)\n",
    "\n",
    "        acc = accuracy_score(labels_test, pred)\n",
    "        prec = precision_score(labels_test, pred)\n",
    "        recl = recall_score(labels_test, pred)\n",
    "\n",
    "        accuracy += acc\n",
    "        precision += prec\n",
    "        recall += recl\n",
    "\n",
    "    accuracy= accuracy/len(kf)\n",
    "    precision= precision/len(kf)\n",
    "    recall= recall/len(kf)\n",
    "    print \"Accuracy:\", accuracy\n",
    "    print \"Precision:\", precision\n",
    "    print \"Recall:\", recall\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericgordo/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Precision: 0.241666666667\n",
      "Recall: 0.225\n"
     ]
    }
   ],
   "source": [
    "clssf = AdaBoostClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.826666666667\n",
      "Precision: 0.258333333333\n",
      "Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "clssf=DecisionTreeClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.269597069597\n",
      "Recall: 0.275\n"
     ]
    }
   ],
   "source": [
    "clssf=GaussianNB()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.866666666667\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "clssf=SVC()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.1\n",
      "Recall: 0.05\n"
     ]
    }
   ],
   "source": [
    "clssf=RandomForestClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816666666667\n",
      "Precision: 0.318333333333\n",
      "Recall: 0.275\n",
      "Pipeline(steps=[('PCA', PCA(copy=True, n_components=8, whiten=False)), ('Classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "tree_params = {\"Classifier__criterion\":['gini','entropy'], \n",
    "               \"Classifier__splitter\": [\"best\", \"random\"],\n",
    "               \"Classifier__min_samples_split\":[2,5,18],\n",
    "               'Classifier__max_leaf_nodes':[5,10,30],\n",
    "               'Classifier__max_depth':[3,4,5,6],\n",
    "               'PCA__n_components': [4,6,8,10]\n",
    "              }\n",
    "\n",
    "pca=PCA()\n",
    "clssf=DecisionTreeClassifier()\n",
    "pipe=Pipeline([\n",
    "            (\"PCA\", pca),(\"Classifier\",clssf)\n",
    "        ])\n",
    "CV = StratifiedShuffleSplit(labels, test_size=0.1, n_iter=100)\n",
    "\n",
    "\n",
    "gs= GridSearchCV(pipe, tree_params , cv=CV, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "clssf=gs.best_estimator_\n",
    "\n",
    "test_class(clssf)\n",
    "print clssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.826666666667\n",
      "Precision: 0.191666666667\n",
      "Recall: 0.15\n",
      "Pipeline(steps=[('PCA', PCA(copy=True, n_components=8, whiten=False)), ('Classifier', GaussianNB())])\n"
     ]
    }
   ],
   "source": [
    "gaussian_params = {\n",
    "               'PCA__n_components': range(2,15)\n",
    "              }\n",
    "\n",
    "pca=PCA()\n",
    "clssf=GaussianNB()\n",
    "pipe=Pipeline([\n",
    "            (\"PCA\", pca),(\"Classifier\",clssf)\n",
    "        ])\n",
    "\n",
    "CV = StratifiedShuffleSplit(labels, test_size=0.1, n_iter=100)\n",
    "\n",
    "gs= GridSearchCV(pipe, gaussian_params , cv=CV, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "clssf=gs.best_estimator_\n",
    "\n",
    "test_class(clssf)\n",
    "print clssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification report\n",
      "Pipeline(steps=[('PCA', PCA(copy=True, n_components=8, whiten=False)), ('Classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.83053\tPrecision: 0.35752\tRecall: 0.34000\tF1: 0.34854\tF2: 0.34336\n",
      "\tTotal predictions: 15000\tTrue positives:  680\tFalse positives: 1222\tFalse negatives: 1320\tTrue negatives: 11778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_list=['poi', 'salary', 'total_payments', 'exercised_stock_options', 'bonus', 'director_fees', 'deferred_income', 'shared_receipt_with_poi', 'loan_advances', 'other', 'total_stock_value', 'long_term_incentive', 'expenses', 'restricted_stock', 'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "\n",
    "clf = Pipeline(steps=[('PCA', PCA(copy=True, n_components=8, whiten=False)), \n",
    "                      ('Classifier', DecisionTreeClassifier(\n",
    "                class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best'))])\n",
    "\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
