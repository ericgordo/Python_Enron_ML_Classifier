{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Implementation to Identify Enron Persons of Interest\n",
    "\n",
    "## Eric Gordon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is an application in order to create and test a machine learning algorithm against an interesting historical event: the collapse and fraud of the Enron Corporation. Machine learning is the perfect tool to use, create, train, and test a classifier that can attempt to correctly label persons of interest within a dataset of the Enron corporation only given certain features about the individuals. While this project utilizes a small sample of data, machine learning algorithms can use the 146 people in our dataset to create a tool that could be used to identify which of these 146 are persons of interest given separate data from the Enron corporation, or even potentially take it to test it against other examples of corporate fraud if given the data.\n",
    "\n",
    "The below code investigates the data, and shows the attempts to optimize the Machine Learning algorithm. Follow this report as an exploratory data analysis.\n",
    "\n",
    "#### Python Library Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries: 146\n",
      "METTS MARK\n",
      "BAXTER JOHN C\n",
      "ELLIOTT STEVEN\n",
      "CORDES WILLIAM R\n",
      "HANNON KEVIN P\n",
      "MORDAUNT KRISTINA M\n",
      "MEYER ROCKFORD G\n",
      "MCMAHON JEFFREY\n",
      "HORTON STANLEY C\n",
      "PIPER GREGORY F\n",
      "HUMPHREY GENE E\n",
      "UMANOFF ADAM S\n",
      "BLACHMAN JEREMY M\n",
      "SUNDE MARTIN\n",
      "GIBBS DANA R\n",
      "LOWRY CHARLES P\n",
      "COLWELL WESLEY\n",
      "MULLER MARK S\n",
      "JACKSON CHARLENE R\n",
      "WESTFAHL RICHARD K\n",
      "WALTERS GARETH W\n",
      "WALLS JR ROBERT H\n",
      "KITCHEN LOUISE\n",
      "CHAN RONNIE\n",
      "BELFER ROBERT\n",
      "SHANKMAN JEFFREY A\n",
      "WODRASKA JOHN\n",
      "BERGSIEKER RICHARD P\n",
      "URQUHART JOHN A\n",
      "BIBI PHILIPPE A\n",
      "RIEKER PAULA H\n",
      "WHALEY DAVID A\n",
      "BECK SALLY W\n",
      "HAUG DAVID L\n",
      "ECHOLS JOHN B\n",
      "MENDELSOHN JOHN\n",
      "HICKERSON GARY J\n",
      "CLINE KENNETH W\n",
      "LEWIS RICHARD\n",
      "HAYES ROBERT E\n",
      "MCCARTY DANNY J\n",
      "KOPPER MICHAEL J\n",
      "LEFF DANIEL P\n",
      "LAVORATO JOHN J\n",
      "BERBERIAN DAVID\n",
      "DETMERING TIMOTHY J\n",
      "WAKEHAM JOHN\n",
      "POWERS WILLIAM\n",
      "GOLD JOSEPH\n",
      "BANNANTINE JAMES M\n",
      "DUNCAN JOHN H\n",
      "SHAPIRO RICHARD S\n",
      "SHERRIFF JOHN R\n",
      "SHELBY REX\n",
      "LEMAISTRE CHARLES\n",
      "DEFFNER JOSEPH M\n",
      "KISHKILL JOSEPH G\n",
      "WHALLEY LAWRENCE G\n",
      "MCCONNELL MICHAEL S\n",
      "PIRO JIM\n",
      "DELAINEY DAVID W\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      "WROBEL BRUCE\n",
      "LINDHOLM TOD A\n",
      "MEYER JEROME J\n",
      "LAY KENNETH L\n",
      "BUTTS ROBERT H\n",
      "OLSON CINDY K\n",
      "MCDONALD REBECCA\n",
      "CUMBERLAND MICHAEL S\n",
      "GAHN ROBERT S\n",
      "MCCLELLAN GEORGE\n",
      "HERMANN ROBERT J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "HAEDICKE MARK E\n",
      "BOWEN JR RAYMOND M\n",
      "GILLIS JOHN\n",
      "FITZGERALD JAY L\n",
      "MORAN MICHAEL P\n",
      "REDMOND BRIAN L\n",
      "BAZELIDES PHILIP J\n",
      "BELDEN TIMOTHY N\n",
      "DURAN WILLIAM D\n",
      "THORN TERENCE H\n",
      "FASTOW ANDREW S\n",
      "FOY JOE\n",
      "CALGER CHRISTOPHER F\n",
      "RICE KENNETH D\n",
      "KAMINSKI WINCENTY J\n",
      "LOCKHART EUGENE E\n",
      "COX DAVID\n",
      "OVERDYKE JR JERE C\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "STABLER FRANK\n",
      "SKILLING JEFFREY K\n",
      "BLAKE JR. NORMAN P\n",
      "SHERRICK JEFFREY B\n",
      "PRENTICE JAMES\n",
      "GRAY RODNEY\n",
      "PICKERING MARK R\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "KEAN STEVEN J\n",
      "TOTAL\n",
      "FOWLER PEGGY\n",
      "WASAFF GEORGE\n",
      "WHITE JR THOMAS E\n",
      "CHRISTODOULOU DIOMEDES\n",
      "ALLEN PHILLIP K\n",
      "SHARP VICTORIA T\n",
      "JAEDICKE ROBERT\n",
      "WINOKUR JR. HERBERT S\n",
      "BROWN MICHAEL\n",
      "BADUM JAMES P\n",
      "HUGHES JAMES A\n",
      "REYNOLDS LAWRENCE\n",
      "DIMICHELE RICHARD G\n",
      "BHATNAGAR SANJAY\n",
      "CARTER REBECCA C\n",
      "BUCHANAN HAROLD G\n",
      "YEAP SOON\n",
      "MURRAY JULIA H\n",
      "GARLAND C KEVIN\n",
      "DODSON KEITH\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "DIETRICH JANET R\n",
      "DERRICK JR. JAMES V\n",
      "FREVERT MARK A\n",
      "PAI LOU L\n",
      "BAY FRANKLIN R\n",
      "HAYSLETT RODERICK J\n",
      "FUGH JOHN L\n",
      "FALLON JAMES B\n",
      "KOENIG MARK E\n",
      "SAVAGE FRANK\n",
      "IZZO LAWRENCE L\n",
      "TILNEY ELIZABETH A\n",
      "MARTIN AMANDA K\n",
      "BUY RICHARD B\n",
      "GRAMM WENDY L\n",
      "CAUSEY RICHARD A\n",
      "TAYLOR MITCHELL S\n",
      "DONAHUE JR JEFFREY M\n",
      "GLISAN JR BEN F\n"
     ]
    }
   ],
   "source": [
    "#Create Pandas Dataframe\n",
    "enron_df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees=np.array(data_dict.keys())\n",
    "enron_df.set_index(employees, inplace=True)\n",
    "\n",
    "#Investigation of Entry Names\n",
    "print \"Number of Entries:\", len(enron_df) \n",
    "\n",
    "for person in enron_df.iterrows():\n",
    "    print person[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two seapearate names stand out that seem to be issues:<br>\n",
    "'THE TRAVEL AGENCY IN THE PARK' <br>\n",
    "'TOTAL'<br>\n",
    "These entries will be deleted as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI's: 18\n"
     ]
    }
   ],
   "source": [
    "#Number of POIs\n",
    "count=0\n",
    "for person in data_dict:\n",
    "    if data_dict[person][\"poi\"]==True:\n",
    "        count+=1      \n",
    "print \"POI's:\",count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHALEY DAVID A 18\n",
      "WROBEL BRUCE 18\n",
      "LOCKHART EUGENE E 20\n",
      "THE TRAVEL AGENCY IN THE PARK 18\n",
      "GRAMM WENDY L 18\n"
     ]
    }
   ],
   "source": [
    "# people with too many Nans\n",
    "for person in data_dict:\n",
    "    NaN=0\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            NaN += 1\n",
    "    if NaN >= 18:\n",
    "        print person, NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonus                          NaN\n",
      "deferral_payments              NaN\n",
      "deferred_income                NaN\n",
      "director_fees                  NaN\n",
      "email_address                  NaN\n",
      "exercised_stock_options        NaN\n",
      "expenses                       NaN\n",
      "from_messages                  NaN\n",
      "from_poi_to_this_person        NaN\n",
      "from_this_person_to_poi        NaN\n",
      "loan_advances                  NaN\n",
      "long_term_incentive            NaN\n",
      "other                          NaN\n",
      "poi                          False\n",
      "restricted_stock               NaN\n",
      "restricted_stock_deferred      NaN\n",
      "salary                         NaN\n",
      "shared_receipt_with_poi        NaN\n",
      "to_messages                    NaN\n",
      "total_payments                 NaN\n",
      "total_stock_value              NaN\n",
      "Name: LOCKHART EUGENE E, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Take a look at Eugene Lockhart\n",
    "print enron_df.loc['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the entry 'LOCKHART EUGENE E' is also an outlier. It only has one data entry -- FALSE for POI -- and no other data. This entry therefore can not help shape our algorithm, and will also be removed as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Outliers Removed\n",
      "Final number of Data Entries: 143\n"
     ]
    }
   ],
   "source": [
    "###Remove outliers\n",
    "try:\n",
    "    enron_df.drop('THE TRAVEL AGENCY IN THE PARK', inplace=True)\n",
    "    enron_df.drop('TOTAL', inplace=True)\n",
    "    enron_df.drop('LOCKHART EUGENE E', inplace=True)\n",
    "    print \"All Outliers Removed\"\n",
    "    print \"Final number of Data Entries:\", len(enron_df)\n",
    "except:\n",
    "    print \"Outliers Already Removed\"'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that our final data set had 143 entries of Eron employees.\n",
    "\n",
    "#### Feature Investigation and Selection\n",
    "\n",
    "Now we will examine the features of the data with more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary <type 'str'>\n",
      "to_messages <type 'str'>\n",
      "deferral_payments <type 'str'>\n",
      "total_payments <type 'str'>\n",
      "exercised_stock_options <type 'str'>\n",
      "bonus <type 'str'>\n",
      "restricted_stock <type 'str'>\n",
      "shared_receipt_with_poi <type 'str'>\n",
      "restricted_stock_deferred <type 'str'>\n",
      "total_stock_value <type 'str'>\n",
      "expenses <type 'str'>\n",
      "loan_advances <type 'str'>\n",
      "from_messages <type 'str'>\n",
      "other <type 'str'>\n",
      "from_this_person_to_poi <type 'str'>\n",
      "poi <type 'str'>\n",
      "director_fees <type 'str'>\n",
      "deferred_income <type 'str'>\n",
      "long_term_incentive <type 'str'>\n",
      "email_address <type 'str'>\n",
      "from_poi_to_this_person <type 'str'>\n",
      "Number of Feautres: 21\n",
      "\n",
      "Number of salary NaNs:  51\n",
      "Number of to_messages NaNs:  60\n",
      "Number of deferral_payments NaNs:  107\n",
      "Number of total_payments NaNs:  21\n",
      "Number of exercised_stock_options NaNs:  44\n",
      "Number of bonus NaNs:  64\n",
      "Number of restricted_stock NaNs:  36\n",
      "Number of shared_receipt_with_poi NaNs:  60\n",
      "Number of restricted_stock_deferred NaNs:  128\n",
      "Number of total_stock_value NaNs:  20\n",
      "Number of expenses NaNs:  51\n",
      "Number of loan_advances NaNs:  142\n",
      "Number of from_messages NaNs:  60\n",
      "Number of other NaNs:  53\n",
      "Number of from_this_person_to_poi NaNs:  60\n",
      "Number of poi NaNs:  0\n",
      "Number of director_fees NaNs:  129\n",
      "Number of deferred_income NaNs:  97\n",
      "Number of long_term_incentive NaNs:  80\n",
      "Number of email_address NaNs:  35\n",
      "Number of from_poi_to_this_person NaNs:  60\n"
     ]
    }
   ],
   "source": [
    "#Number of Features and their Types\n",
    "features=0\n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        print feature, type(feature)\n",
    "        features+=1\n",
    "    break\n",
    "print \"Number of Feautres:\", features\n",
    "print''\n",
    "\n",
    "#Number of NaN's for Each Feature\n",
    "for feature in data_dict['METTS MARK'].keys():\n",
    "    Nans=0    \n",
    "    for person in data_dict:\n",
    "        if data_dict[person][feature]=='NaN':\n",
    "            Nans += 1\n",
    "    print \"Number of\", feature, \"NaNs: \", Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'bonus', u'deferral_payments', u'deferred_income', u'director_fees',\n",
      "       u'email_address', u'exercised_stock_options', u'expenses',\n",
      "       u'from_messages', u'from_poi_to_this_person',\n",
      "       u'from_this_person_to_poi', u'loan_advances', u'long_term_incentive',\n",
      "       u'other', u'poi', u'restricted_stock', u'restricted_stock_deferred',\n",
      "       u'salary', u'shared_receipt_with_poi', u'to_messages',\n",
      "       u'total_payments', u'total_stock_value', u'combined_emails'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### Create new feature(s)\n",
    "# POI_From_To_Ratio is just the # of emails to a poi divided by emails from a poi to this person\n",
    "enron_df['combined_emails'] = (enron_df['from_messages'].astype(float)) + (enron_df['from_poi_to_this_person'].astype(float)) +\\\n",
    "(enron_df['to_messages'].astype(float)) + (enron_df['from_this_person_to_poi'].astype(float)) \n",
    "   \n",
    "enron_df['combined_emails'].fillna(value=0, inplace=True)\n",
    "        \n",
    "print \"Example Combined Emails Entires: \\n\", enron_df['combined_emails'].head()\n",
    "print \"\"\n",
    "print \"all features now \\n\", enron_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "['to_messages', 'deferral_payments', 'expenses', 'poi', 'long_term_incentive', 'email_address', 'from_poi_to_this_person', 'deferred_income', 'combined_emails', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'from_messages', 'other', 'director_fees', 'bonus', 'total_stock_value', 'from_this_person_to_poi', 'restricted_stock', 'salary', 'total_payments', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "### RETURN to DICTIONARY\n",
    "data_dict=enron_df.to_dict('index')  \n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "print len(my_dataset)\n",
    "print my_dataset['METTS MARK'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data provided, there are 21 features associated with each individual . The number of valid data entries for each feature also varies considerably per feature, as seen by the number of NaN's for listed for each feature above. Thus it will be worth investigating whether or not every fearutre should be included in our Machine Learning Algorithm. It will be confusing to manually select and determine which features to keep for predicting persons of interest, so we will nprogrammatically select the features to move forward with. \n",
    "\n",
    "Before implementing this though,I want to make note of the mannual feature that was created called ‘combined_emails’, in which all the numeric values of emails sent and received, both to persons of interest and not, were al combined into a single data point. The theory behind this is that I believed persons of interest may have been more active in overall email use compared to others, because of their ranks in the company, and possibly due to their over involvement in company dealings. So I wanted to look to see if overuse of email could help predict persons of interest. \n",
    "\n",
    "#### Selecting Features to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Feature Length: 21\n",
      "\n",
      " Features List Now is: \n",
      "16 ['poi', 'salary', 'total_payments', 'exercised_stock_options', 'bonus', 'director_fees', 'deferred_income', 'shared_receipt_with_poi', 'loan_advances', 'other', 'total_stock_value', 'long_term_incentive', 'expenses', 'restricted_stock', 'from_poi_to_this_person', 'from_this_person_to_poi']\n"
     ]
    }
   ],
   "source": [
    "# Create Data\n",
    "#Note: Email is just a string, so was excluded\n",
    "temp_features = ['poi','to_messages', \n",
    "                 'deferral_payments','combined_emails', 'expenses',\n",
    "                 'long_term_incentive', 'from_poi_to_this_person',\n",
    "                 'deferred_income','restricted_stock_deferred', \n",
    "                 'shared_receipt_with_poi', 'loan_advances', \n",
    "                 'from_messages', 'other','director_fees', \n",
    "                 'bonus', 'total_stock_value', \n",
    "                 'from_this_person_to_poi', 'restricted_stock',\n",
    "                 'salary', 'total_payments', 'exercised_stock_options']\n",
    "\n",
    "print \"Starting Features to Test :\", len(temp_features) - 1 \n",
    "\n",
    "#Create Data\n",
    "data = featureFormat(data_dict, temp_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SelectKBest algorithm tool from python’s Scikit-Learn library will be used with multiple iterations of randomized testing and training data to select the best features to use for our person of interest identifier. \n",
    "\n",
    "Before selecting best features though, all of the features will be scaled to be of numeric values between 0 and 1. These features are scaled to help neutralize the difference between the monetary feature values, that be in the millions, and the email data values that were at most in the hundreds. \n",
    "\n",
    "To figure out how many features to keep, I tested both the amount of features to keep, and the features to keep themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting Number of Features to Keep\n",
    "x=[]\n",
    "f1score=[]\n",
    "n_features_dictionary={}\n",
    "\n",
    "#Iterate through number to use for KBest\n",
    "for N in range(1, 21):\n",
    "    kf=StratifiedShuffleSplit(labels, test_size=0.1,n_iter=5, random_state=15)\n",
    "    f1=0\n",
    "    features_list=['poi']\n",
    "    feature_counts={}\n",
    "    for train_indices, test_indices in kf:\n",
    "        features_train= [features[ii] for ii in train_indices]\n",
    "        features_test= [features[ii] for ii in test_indices]\n",
    "        labels_train= [labels[ii] for ii in train_indices]\n",
    "        labels_test= [labels[ii] for ii in test_indices]\n",
    "\n",
    "        #Create a Classifier to use with N number of Features\n",
    "        kbest=SelectKBest(k=N)\n",
    "        scaler=MinMaxScaler()\n",
    "        clssf=GaussianNB()\n",
    "        pipe=Pipeline(steps=[('Scale', scaler), ('KBest', kbest), ('Tree', clssf)]) \n",
    "        \n",
    "        #Get K Best Seperately\n",
    "        kbest.fit(features_train, labels_train )\n",
    "        features_to_use = kbest.get_support()\n",
    "        \n",
    "        #Predict with N features\n",
    "        pipe.fit(features_train,labels_train)\n",
    "        pred=pipe.predict(features_test)\n",
    "        \n",
    "        #Record Score\n",
    "        f1_sc = f1_score(labels_test, pred)\n",
    "        f1 += f1_sc\n",
    "        \n",
    "        #Create Feature Counts Dictionary for KBest is N\n",
    "        for i, item in enumerate(features_to_use):\n",
    "            if item:\n",
    "                feature=temp_features[i + 1 ]\n",
    "                if feature in feature_counts:\n",
    "                    feature_counts[feature]+=1\n",
    "                else:\n",
    "                    feature_counts[feature]=1           \n",
    "\n",
    "    f1 = f1/len(kf)\n",
    "    #Record Average Score in list For F1 Score\n",
    "    f1score.append(f1)\n",
    "    #Create x List for Graph\n",
    "    x.append(N)\n",
    "    \n",
    "    #Create Feature List for N Features\n",
    "    for feature in feature_counts:\n",
    "        if feature_counts[feature] > 1:\n",
    "            features_list.append(feature)\n",
    "    \n",
    "    #Save Feature list to Features Dictionary for k=N Features\n",
    "    n_features_dictionary[N] = features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot Results Trials To See Number of Features to keep\n",
    "%pylab inline\n",
    "\n",
    "plt.scatter(x, f1score, c=\"Red\") \n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('f1 Score')\n",
    "plt.title('F1 SCORES',fontsize=18)\n",
    "\n",
    "print \"Number of Features for Best F1:\", f1score.index(max(f1score)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average F1 score seems to be highest for a basic classifier when k is set to keeping 14 features, as seen by a graph above. So we will use the those 14 features going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Save features_list as Final List\n",
    "### Print Out the Feature list from the n_features_dictionary\n",
    "\n",
    "features_list=n_features_dictionary[14]\n",
    "\n",
    "print \"# of features is Now:\", len(n_features_dictionary[14]), \n",
    "print \"\\n Feature list is now:\", n_features_dictionary[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Exploration\n",
    "\n",
    "Before settling on a single algorithm, it is worth trying several different machine learning algorithms to test out how some basic classifiers may work with this data. I will test following algorithm classifiers to see if any work well: <br>\n",
    "AdaBoost, Decision Tree, Gaussian Naïve Bayes, Support Vector, and Random Forest.\n",
    "\n",
    "We will mainly compare recall and percision scores to decide which features to choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re Create Data With New List\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Try a varity of classifiers\n",
    "### Definition of Classifier Tester Function\n",
    "def test_class(clssf):\n",
    "    kf=StratifiedShuffleSplit(labels, test_size=0.1,n_iter=20)\n",
    "    accuracy=0\n",
    "    precision=0\n",
    "    recall=0\n",
    "    for train_indices, test_indices in kf:\n",
    "        features_train= [features[ii] for ii in train_indices]\n",
    "        features_test= [features[ii] for ii in test_indices]\n",
    "        labels_train= [labels[ii] for ii in train_indices]\n",
    "        labels_test= [labels[ii] for ii in test_indices]\n",
    "        \n",
    "        pca=PCA(n_components= 6)\n",
    "        pipe=Pipeline([\n",
    "            (\"Classifier\",clssf)\n",
    "        ])\n",
    "\n",
    "        pipe.fit(features_train,labels_train)\n",
    "        pred=pipe.predict(features_test)\n",
    "\n",
    "        acc = accuracy_score(labels_test, pred)\n",
    "        prec = precision_score(labels_test, pred)\n",
    "        recl = recall_score(labels_test, pred)\n",
    "\n",
    "        accuracy += acc\n",
    "        precision += prec\n",
    "        recall += recl\n",
    "\n",
    "    accuracy= accuracy/len(kf)\n",
    "    precision= precision/len(kf)\n",
    "    recall= recall/len(kf)\n",
    "    print \"Accuracy:\", accuracy\n",
    "    print \"Precision:\", precision\n",
    "    print \"Recall:\", recall\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.3\n",
      "Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "clssf = AdaBoostClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813333333333\n",
      "Precision: 0.224166666667\n",
      "Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "clssf=DecisionTreeClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.3125\n",
      "Recall: 0.275\n"
     ]
    }
   ],
   "source": [
    "clssf=GaussianNB()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.866666666667\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "clssf=SVC()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846666666667\n",
      "Precision: 0.191666666667\n",
      "Recall: 0.15\n"
     ]
    }
   ],
   "source": [
    "clssf=RandomForestClassifier()\n",
    "test_class(clssf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that from just initial tests, that both the Gaussian Naïve Bayes and Decision Tree algorithms have some good initial validly scores, even without being optimized. We will try to optimize these two algorithms below. \n",
    "\n",
    "#### Parameter Optimization\n",
    "\n",
    "The GridSearchCV tool in SciKit Learn will be used to optimize some parameter selection. Particularly some parameters such as the number of splits to take in our decision tree will be run through and evaluated, and the GridSearchCV will return the classifier with the best parameters. Hopefully this will improve our algorithm, and we can finalize our person of interest identifier. Also, we will experiment with performing Principal Component analysis, to possibly reduce the dimensionality of the features. This could help reduce some overly noisy data (too many features) and help the algorithm perform better. The option of keeping all 14 features will be availible though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_classifier() takes at least 3 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f0a4e0a4624d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mclssf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclssf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclssf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test_classifier() takes at least 3 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "tree_params = {\"Classifier__criterion\":['gini','entropy'], \n",
    "               \"Classifier__splitter\": [\"best\", \"random\"],\n",
    "               \"Classifier__min_samples_split\":[2,5,18],\n",
    "               'Classifier__max_leaf_nodes':[5,10,30],\n",
    "               'Classifier__max_depth':[3,4,5,6],\n",
    "               'PCA__n_components': [4,6,8,10,14]\n",
    "              }\n",
    "\n",
    "pca=PCA()\n",
    "clssf=DecisionTreeClassifier()\n",
    "pipe=Pipeline([\n",
    "            (\"PCA\", pca),(\"Classifier\",clssf)\n",
    "        ])\n",
    "CV = StratifiedShuffleSplit(labels, test_size=0.1, n_iter=100)\n",
    "\n",
    "\n",
    "gs= GridSearchCV(pipe, tree_params , cv=CV, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "clssf=gs.best_estimator_\n",
    "\n",
    "test_class(clssf)\n",
    "print clssf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericgordo/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863333333333\n",
      "Precision: 0.308333333333\n",
      "Recall: 0.2\n",
      "Pipeline(steps=[('PCA', PCA(copy=True, n_components=2, whiten=False)), ('Classifier', GaussianNB())])\n"
     ]
    }
   ],
   "source": [
    "gaussian_params = {\n",
    "               'PCA__n_components': range(2,14)\n",
    "              }\n",
    "\n",
    "pca=PCA()\n",
    "clssf=GaussianNB()\n",
    "pipe=Pipeline([\n",
    "            (\"PCA\", pca),(\"Classifier\",clssf)\n",
    "        ])\n",
    "\n",
    "CV = StratifiedShuffleSplit(labels, test_size=0.1, n_iter=100)\n",
    "\n",
    "gs= GridSearchCV(pipe, gaussian_params , cv=CV, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "clssf=gs.best_estimator_\n",
    "\n",
    "test_class(clssf)\n",
    "print clssf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After optimizing the two classifiers, it seems that the performing principal component analysis then a Decision Tree Algorithm returns the best results of a classifier for this machine learning task. The parameter optimization tuned with GridSerachCV helped increase overall higher scores in performance. This will thus be our algorithm that we will use below.\n",
    "\n",
    "# Final Person Of Interest Identifier Test and Closing Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification report\n",
      "Pipeline(steps=[('PCA', PCA(copy=True, n_components=12, whiten=False)), ('Classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.82047\tPrecision: 0.32348\tRecall: 0.31750\tF1: 0.32046\tF2: 0.31868\n",
      "\tTotal predictions: 15000\tTrue positives:  635\tFalse positives: 1328\tFalse negatives: 1365\tTrue negatives: 11672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_list=['poi', 'salary', 'total_payments', \n",
    "               'exercised_stock_options', 'bonus', 'deferred_income', \n",
    "               'shared_receipt_with_poi', 'loan_advances', 'other', \n",
    "               'total_stock_value', 'long_term_incentive', \n",
    "               'expenses', 'restricted_stock', 'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "\n",
    "clf= Pipeline(steps=[('PCA', PCA(copy=True, n_components=8, whiten=False)), ('Classifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best'))])\n",
    "\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final Thoughts and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the final classifier (in the output above) the test above gives us several metrics to evaluate. That is, we gave the classifier 15000 entries that were formatted to mimic the data it was trained on, to see how the classifier would do in predicting whether an Enron employ, with data on the features we selected above, was actually a person of interest or not. The model was able to correctly classify and label 674 persons of interest who were in fact so according to data. Additionally, the model was able to correctly not flag 11777 of the employees as persons of interest, who indeed should not have been flagged. \n",
    "\n",
    "The model however did falsely predict 1223 individuals as a person of interest, when in fact the data point was not supposed to be flagged. This is what the “precision score” of 0.355, means. On the other hand, there were also 1326 individuals that the model did not flag as a person of interest, but in fact should of. Similarly, this is what the “recall score” of 0.337 means. Having more instances of incorrectly identifying persons of interest, and additionally having more instances of looking over persons of interest than correctly identifying them shows the limitations of this machine learning algorithm.\n",
    "\n",
    "These mistakes with the classifier actually help reveal how unique and difficult it is to fully comprehend the Enron corporate collapse. This data set only contained 18 persons of interest in a set of 143, but our algorithm seemed identify a lot of other individuals within testing sets has having very similar characteristics as these persons of interest. There can be many further efforts in trying to better identify who was involved in the Enron corporate scandal, however, it does seem clear that the scandal at Enron was not only hard to fully characterize, but also very complicated. This project though, does show some insight though to how a machine learning algorithm can be used and implement to identify and flag unique trends in datasets. \n",
    "\n",
    "### Resources \n",
    "\n",
    "Enron- Email Dataset: <br>\n",
    " https://www.cs.cmu.edu/~./enron/\n",
    "\n",
    "Article to identify POI’s from Enron:<br>\n",
    " http://usatoday30.usatoday.com/money/industries/energy/2005-12-28-enron-participants_x.htm\n",
    "\n",
    "General Machine Learning Support and Help:<br>\n",
    "https://www.udacity.com/course/intro-to-machine-learning--ud120 (And all Forums Included)\n",
    "\n",
    "Python Coding Support and Help:<br>\n",
    "http://stackoverflow.com/\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
